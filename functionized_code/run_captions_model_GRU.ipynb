{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains the following operations\n",
    "* Load the US Video data with Captions\n",
    "* Create iterators for train, validation and test datasets\n",
    "* Run the analysis with neural network models (including GRU and Linear NN)\n",
    "* Run the analysis with Machine Learning Models (logistic regression and random forest) with reduced TFIDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_input as data_in\n",
    "import nnmodels as nnm\n",
    "import mlmodels as mlm\n",
    "import bow_models as bowm\n",
    "import train_eval\n",
    "import visualization as vis\n",
    "from torchtext import data\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import csv\n",
    "import sys\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model using captions with RNN models requires at least 15GB for memroy (either in cpu or gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Captions Data & and Create Iterators for train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'D:\\Researching Data\\Youtube data\\caption_sector\\transcripts.txt' # should specify the directory for the captions\n",
    "path = r'D:\\Researching Data\\Youtube data\\caption_sector' # should specify the path to captions data\n",
    "TRAIN_VALID_TEST_R = (0.4, 0.4, 0.2)\n",
    "MAX_VOCAB_SIZE = 25000\n",
    "BATCH_SIZE = 32 \n",
    "# using 64 for batch size is okay for LSTM and GRU, but the memory explodes sometimes\n",
    "# the datasets are splitted randomly, using 32 for batch size is more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(1000000000)\n",
    "txt_list = []\n",
    "with open(data_dir, \"r\", encoding=\"utf-8\") as f:\n",
    "    csv_reader = csv.reader(f, delimiter='\\n')\n",
    "    for row in csv_reader:\n",
    "        txt_list.append(', '.join(row))\n",
    "\n",
    "video_id = []\n",
    "txt_content = []\n",
    "for txt_row in txt_list:\n",
    "    video_id.append(txt_row[:11])\n",
    "    txt_content.append(txt_row[12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = pd.read_csv(r'D:\\Researching Data\\Youtube data\\USvideos.csv') # should specify the directory for US video data\n",
    "new_arr = fdata.drop_duplicates(\"video_id\", \"first\")[[\"video_id\", \"category_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_TEXT = txt_content\n",
    "new_id = video_id\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train, valid and test data are 1642 1642 822\n"
     ]
    }
   ],
   "source": [
    "train_indices, valid_indices, test_indices = data_in.split_train_test(len(new_TEXT), TRAIN_VALID_TEST_R)\n",
    "new_idtxt = pd.DataFrame(list(zip(new_id, new_TEXT)), columns=[\"video_id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pd = pd.merge(new_arr, new_idtxt, left_on=\"video_id\", right_on=\"video_id\")[[\"text\", \"category_id\"]]\n",
    "new_pd.loc[new_pd[\"category_id\"] != 25, \"category_id\"] = 0\n",
    "new_pd.loc[new_pd[\"category_id\"] == 25, \"category_id\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline precision is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07355090112031173"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pd[new_pd[\"category_id\"] == 1].shape[0] / new_pd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pd.iloc[train_indices].to_csv(path + \"\\\\train.csv\", header=None, index=None)\n",
    "new_pd.iloc[valid_indices].to_csv(path + \"\\\\valid.csv\", header=None, index=None)\n",
    "new_pd.iloc[test_indices].to_csv(path + \"\\\\test.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                            path = path,\n",
    "                                            train = 'train.csv',\n",
    "                                            validation = 'valid.csv',\n",
    "                                            test = 'test.csv',\n",
    "                                            format = 'csv',\n",
    "                                            fields = fields,\n",
    "                                            skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "device = torch.device('cpu') # switch to the local device\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator, valid_iterator, test_iterator = data_in.build_iterator(BATCH_SIZE, device, train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Neural Network Models (GRU) for Captions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_wordem = nnm.WordEmbAvg_2linear(INPUT_DIM, EMBEDDING_DIM, \n",
    "                                      HIDDEN_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "model_rnn = nnm.SimpleRNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, \n",
    "                          OUTPUT_DIM, PAD_IDX)\n",
    "model_BLSTM = nnm.LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "                       N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "model_GRU = nnm.GRU(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "                       N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "model_CNN = nnm.CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, \n",
    "                    OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "#MODEL_DICT = {\"avg_embedding\": model_wordem, \"SimpleRNN\": model_rnn,\n",
    "#              \"BLSTM\": model_BLSTM, \"CNN\": model_CNN}\n",
    "MODEL_DICT = {\"avg_embedding\": model_wordem, \"GRU\": model_GRU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently training the model:  avg_embedding\n",
      "Epoch 0: Dev Accuracy: 0.7538060901256708 Dev Loss:0.49483970953867984\n",
      "Epoch 1: Dev Accuracy: 0.7817841882889087 Dev Loss:0.5008824453330957\n",
      "Epoch 2: Dev Accuracy: 0.7788461538461539 Dev Loss:0.5635954078573447\n",
      "Epoch 3: Dev Accuracy: 0.7821180556829159 Dev Loss:0.8920228398190095\n",
      "Epoch 4: Dev Accuracy: 0.7749065172213775 Dev Loss:0.9194676373153925\n",
      "Test Loss: 0.866 | Test Acc: 77.46%\n",
      "Test Prec: nan% | Test Rec: 40.055%\n",
      "currently training the model:  GRU\n",
      "Epoch 0: Dev Accuracy: 0.7183493593564401 Dev Loss:0.5994919120119169\n",
      "Epoch 1: Dev Accuracy: 0.7315705132025939 Dev Loss:0.5822257044223639\n",
      "Epoch 2: Dev Accuracy: 0.7045272439718246 Dev Loss:0.5928595094726636\n",
      "Epoch 3: Dev Accuracy: 0.6955795941444544 Dev Loss:0.6032525925682142\n",
      "Epoch 4: Dev Accuracy: 0.6898370729042933 Dev Loss:0.6088535711169243\n",
      "Test Loss: 0.608 | Test Acc: 71.25%\n",
      "Test Prec: nan% | Test Rec: 5.980%\n"
     ]
    }
   ],
   "source": [
    "#result for label 24\n",
    "best_models, models_perf = train_eval.compare_models(MODEL_DICT, device, train_iterator, valid_iterator, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently training the model:  avg_embedding\n",
      "Epoch 0: Dev Accuracy: 0.9250801285872092 Dev Loss:0.19852247060491487\n",
      "Epoch 1: Dev Accuracy: 0.9449786326059928 Dev Loss:0.16923019692946512\n",
      "Epoch 2: Dev Accuracy: 0.9473824787598389 Dev Loss:0.19230335514293984\n",
      "Epoch 3: Dev Accuracy: 0.9491853633752236 Dev Loss:0.21848319830986349\n",
      "Epoch 4: Dev Accuracy: 0.942841880596601 Dev Loss:0.2495448182682874\n",
      "Test Loss: 0.160 | Test Acc: 95.55%\n",
      "Test Prec: nan% | Test Rec: nan%\n",
      "currently training the model:  GRU\n",
      "Epoch 0: Dev Accuracy: 0.9172676285872092 Dev Loss:0.2661041310773446\n",
      "Epoch 1: Dev Accuracy: 0.9073183765778174 Dev Loss:0.2658712441244951\n",
      "Epoch 2: Dev Accuracy: 0.9133279919624329 Dev Loss:0.27174548127760106\n",
      "Epoch 3: Dev Accuracy: 0.8667868593564401 Dev Loss:0.34031229487691933\n",
      "Epoch 4: Dev Accuracy: 0.9112580132025939 Dev Loss:0.3148644603162001\n",
      "Test Loss: 0.250 | Test Acc: 92.36%\n",
      "Test Prec: nan% | Test Rec: nan%\n"
     ]
    }
   ],
   "source": [
    "#result for label 25\n",
    "best_models, models_perf = train_eval.compare_models(MODEL_DICT, device, train_iterator, valid_iterator, test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing TFIDF & Machine Learning Models with Captions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization_dim_reduction as tdr\n",
    "new_arr = np.array(new_pd[\"text\"])\n",
    "txt_tfidf = tdr.tfidf_tokenization(new_arr)\n",
    "new_TEXT = txt_tfidf.toarray()\n",
    "new_label = np.array(new_pd[\"category_id\"])\n",
    "top5k_indices = np.argsort(np.apply_along_axis(np.mean, 0, new_TEXT))[-5000:]\n",
    "new_TEXT = new_TEXT[:, top5k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train, valid and test data are 1642 1642 822\n"
     ]
    }
   ],
   "source": [
    "train_indices, valid_indices, test_indices = data_in.split_train_test(new_TEXT.shape[0], (0.4,0.4,0.2))    \n",
    "X_train, X_valid = tdr.dimensional_reduction(new_TEXT[train_indices], 500, True, new_TEXT[valid_indices])\n",
    "X_train, X_test = tdr.dimensional_reduction(new_TEXT[train_indices], 500, True, new_TEXT[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = new_label[train_indices].reshape([len(train_indices),1])\n",
    "y_valid = new_label[valid_indices].reshape([len(valid_indices),1])\n",
    "y_test = new_label[test_indices].reshape([len(test_indices),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation of random_forest method begins\n",
      "the best accuracy for method:  random_forest  is  0.9440389294403893\n",
      "the corresponding precision is :  0.0\n",
      "the corresponding recall is :  0.0\n",
      "operation of logistics method begins\n",
      "the best accuracy for method:  logistics  is  0.9464720194647201\n",
      "the corresponding precision is :  0\n",
      "the corresponding recall is :  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_forest': (\"random_forest with parameters : {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 1, 'n_jobs': 2, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\",\n",
       "  0.9440389294403893,\n",
       "  0,\n",
       "  0.0),\n",
       " 'logistics': (\"logistics with parameters : {'C': 0.001, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\",\n",
       "  0.9464720194647201,\n",
       "  0,\n",
       "  0.0)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm.ml_evaluate(mlm.CLFS, mlm.PARAMETER_DICT, X_train, y_train, \n",
    "                              X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_main] *",
   "language": "python",
   "name": "conda-env-py36_main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
